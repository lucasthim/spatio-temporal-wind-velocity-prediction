{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Features and Dataset to ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from data_preprocessing import *\n",
    "from feature_engineering import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final preprocessing on Historical Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations = pd.read_csv(\"./../../data/preprocessed/wind_data_conde_and_adjacent_stations.csv\")\n",
    "df_stations = df_stations.drop(columns=['WIND_SPEED_120m_ms'])\n",
    "df_stations['DATETIME'] = pd.to_datetime(df_stations['DATETIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing station A431-CONDE. Current size: 26179 hour points.\n",
      "Resampled 149 hour points\n",
      "\n",
      "Processing station A409-ARACAJU. Current size: 26328 hour points.\n",
      "Resampled 0 hour points\n",
      "\n",
      "Processing station A401-SALVADOR. Current size: 26309 hour points.\n",
      "Resampled 19 hour points\n",
      "\n",
      "Processing station A450-JEREMOABO. Current size: 26261 hour points.\n",
      "Resampled 67 hour points\n",
      "\n",
      "Processing station A434-AMARGOSA. Current size: 25194 hour points.\n",
      "Resampled 1134 hour points\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols_to_fill = df_stations.drop(columns=['WIND_SPEED_ms','WIND_DIRECTION_degrees','WIND_MAX_GUNS_ms']).columns.tolist()\n",
    "stations_to_compare = [\"AMARGOSA\", \"ARACAJU\", \"CONDE\", \"JEREMOABO\", \"SALVADOR\"]\n",
    "\n",
    "df_stations_processed = prepare_data_for_feature_generation(\n",
    "                                    df=df_stations.query(\"NAME in @stations_to_compare\"),\n",
    "                                    fillna_method='rolling',\n",
    "                                    cols_to_fill=cols_to_fill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Target and Features for Hourly Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_features = ['TOTAL_PRECIPITATION_mm', 'ATM_PRESSURE_mB', 'ATM_PRESSURE_SEA_LEVEL_mB', 'MAX_ATM_PRESSURE_PREV_HOUR_mB', \n",
    "'MIN_ATM_PRESSURE_PREV_HOUR_mB', 'GLOBAL_RADIATION_Kjm2', 'AIR_TEMPERATURE_DRY_BULB_Celsius', 'DEW_POINT_TEMPERATURE_Celsius', \n",
    "'MAX_TEMPERATURE_PREV_HOUR_Celsius', 'MIN_TEMPERATURE_PREV_HOUR_Celsius', 'DEW_POINT_MAX_TEMPERATURE_PREV_HOUR_Celsius', \n",
    "'DEW_POINT_MIN_TEMPERATURE_PREV_HOUR_Celsius', 'MAX_RELATIVE_HUMIDITY_PREV_HOUR_percentage', \n",
    "'MIN_RELATIVE_HUMIDITY_PREV_HOUR_percentage', 'RELATIVE_HUMIDITY_percentage', 'WIND_DIRECTION_degrees', \n",
    "'WIND_MAX_GUNS_ms', 'WIND_SPEED_ms']\n",
    "\n",
    "targets = ['WIND_DIRECTION_degrees', 'WIND_MAX_GUNS_ms', 'WIND_SPEED_ms']\n",
    "\n",
    "auxiliary_columns = ['NAME','CODE','DATETIME','YEAR']\n",
    "\n",
    "df_final_dataset = make_wind_prediction_dataset(df=df_stations_processed,\n",
    "                                        main_features=hourly_features,\n",
    "                                        lags=[1,2,3,4,5,6,12,24],\n",
    "                                        rolling_windows = [4,12,24],\n",
    "                                        granularity='HOUR',\n",
    "                                        targets=targets,\n",
    "                                        target_shift=[1,3,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset size: (131640, 454)\n",
      "There were 10 features with more than 20.0% of null values:\n",
      "There were a total of 10504 with less than 80.0% of avaiable data (features).\n"
     ]
    }
   ],
   "source": [
    "def drop_null_features_and_instances(df,feature_null_percentage=0.2,instance_null_percentage=0.8):\n",
    "    '''Drop features and instances that are above a null percentage.'''\n",
    "\n",
    "    dataset_initial_size = df.shape[0]\n",
    "    \n",
    "    print(\"Initial dataset size:\",df.shape)\n",
    "    nulls = df.isnull().sum() / dataset_initial_size\n",
    "    nulls_20_percent = nulls[nulls > feature_null_percentage]\n",
    "    print(f\"There were {nulls_20_percent.shape[0]} features with more than {feature_null_percentage*100}% of null values:\")\n",
    "    \n",
    "    cols_nulls_20_percent = nulls_20_percent.index.tolist()\n",
    "    non_null_tresh = np.round(df.drop(columns=cols_nulls_20_percent).shape[1])\n",
    "    df_selected = df.drop(columns=cols_nulls_20_percent)\n",
    "    total_instances = df_selected.shape[0]\n",
    "    \n",
    "    df_selected = df_selected.dropna(axis=0,thresh=non_null_tresh* instance_null_percentage)\n",
    "    processed_instances = df_selected.shape[0]\n",
    "    \n",
    "    print(f\"There were a total of {total_instances-processed_instances} with less than {instance_null_percentage*100}% of avaiable data (features).\")\n",
    "    return df_selected\n",
    "    \n",
    "df_selected = drop_null_features_and_instances(df_final_dataset,feature_null_percentage=0.2,instance_null_percentage=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected.to_parquet(\"./../../data/model_train/2022_06_20_wind_dataset_lags_central_tendency_dispersion_hour.gzip\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Target and Features for Daily Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_features = ['TOTAL_PRECIPITATION_mm', 'ATM_PRESSURE_mB', 'ATM_PRESSURE_SEA_LEVEL_mB', 'MAX_ATM_PRESSURE_PREV_HOUR_mB', \n",
    "'MIN_ATM_PRESSURE_PREV_HOUR_mB', 'GLOBAL_RADIATION_Kjm2', 'AIR_TEMPERATURE_DRY_BULB_Celsius', 'DEW_POINT_TEMPERATURE_Celsius', \n",
    "'MAX_TEMPERATURE_PREV_HOUR_Celsius', 'MIN_TEMPERATURE_PREV_HOUR_Celsius', 'DEW_POINT_MAX_TEMPERATURE_PREV_HOUR_Celsius', \n",
    "'DEW_POINT_MIN_TEMPERATURE_PREV_HOUR_Celsius', 'MAX_RELATIVE_HUMIDITY_PREV_HOUR_percentage', \n",
    "'MIN_RELATIVE_HUMIDITY_PREV_HOUR_percentage', 'RELATIVE_HUMIDITY_percentage', 'WIND_DIRECTION_degrees', \n",
    "'WIND_MAX_GUNS_ms', 'WIND_SPEED_ms']\n",
    "\n",
    "targets = ['WIND_DIRECTION_degrees', 'WIND_MAX_GUNS_ms', 'WIND_SPEED_ms']\n",
    "\n",
    "auxiliary_columns = ['NAME','CODE','DATETIME','YEAR']\n",
    "\n",
    "df_final_dataset_day = make_wind_prediction_dataset(df=df_stations_processed,\n",
    "                                        main_features=hourly_features,\n",
    "                                        lags=[1,2,3,4,5,6,7,15,30,60,90],\n",
    "                                        rolling_windows = [7,15,30,60],\n",
    "                                        granularity='DAY',\n",
    "                                        targets=targets,\n",
    "                                        target_shift=[1,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset size: (5485, 592)\n",
      "There were 30 features with more than 20.0% of null values:\n",
      "There were a total of 884 with less than 90.0% of avaiable data (features).\n"
     ]
    }
   ],
   "source": [
    "df_selected = drop_null_features_and_instances(df_final_dataset_day,feature_null_percentage=0.2,instance_null_percentage=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected.to_parquet(\"./../../data/model_train/2022_06_20_wind_dataset_lags_central_tendency_dispersion_day.gzip\",index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff5b71a57004aac41c92d4008d66e8c8a20573ad91c6a09451338db6162a1ae6"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('base_ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
